{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2 as cv2 # opencv computer vision library\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "from typing import Dict, Any\n",
    "\n",
    "dirname = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"lib\"))\n",
    "sys.path.append(dirname)\n",
    "\n",
    "from display import imshow\n",
    "from vgg import VGGFeatures\n",
    "from utils import get_file_type\n",
    "from data import ImageFolderDataset\n",
    "from DeepStyleX import DeepStyleX\n",
    "\n",
    "import moviepy as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import video and image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/example_video.mp4 video\n",
      "../data/Central-Park.jpg image\n"
     ]
    }
   ],
   "source": [
    "video_path = '../data/example_video.mp4'\n",
    "image_path = \"../data/Central-Park.jpg\"\n",
    "\n",
    "\n",
    "print(video_path,get_file_type(video_path))\n",
    "print(image_path,get_file_type(image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For handling videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_frame_iterator(video_clip, batch_size):\n",
    "    \"\"\"\n",
    "    Generator to yield batches of frames from a video.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video.\n",
    "        batch_size (int): Number of frames per batch.\n",
    "\n",
    "    Yields:\n",
    "        list: A batch of frames (as numpy arrays).\n",
    "    \"\"\"\n",
    "    batch = []\n",
    "\n",
    "    for frame in video_clip.iter_frames(fps=video_clip.fps, dtype=\"uint8\"):\n",
    "        batch.append(frame)\n",
    "        if len(batch) == batch_size:\n",
    "            yield torch.from_numpy(np.stack(batch, axis=0)).permute(0, 3, 1, 2).float()  # Yield a full batch\n",
    "            batch = []\n",
    "\n",
    "    if len(batch)>0:\n",
    "        yield torch.from_numpy(np.stack(batch, axis=0)).permute(0, 3, 1, 2).float()  # Yield a partial batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model set to evaluation\n"
     ]
    }
   ],
   "source": [
    "model, _ = DeepStyleX.load('../data/saves/abstract.dsx')\n",
    "model.eval()\n",
    "print(\"Model set to evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_video_generator(clip, batch_size):\n",
    "    total_frames = int(clip.duration * clip.fps+0.1)\n",
    "    for batch in tqdm(clip_frame_iterator(clip, batch_size=batch_size), total=(total_frames+batch_size-1)//batch_size):\n",
    "        with torch.no_grad():\n",
    "            output = model(batch)\n",
    "            output = output.permute(0, 2, 3, 1).cpu().detach().numpy().astype(np.uint8)\n",
    "        for frame in output:\n",
    "            yield frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_video = mp.VideoFileClip(video_path)\n",
    "original_audio = original_video.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [02:43<00:00,  2.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.733333333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the video clip\n",
    "clip = mp.ImageSequenceClip(list(new_video_generator(original_video, batch_size=4)), fps=original_video.fps)\n",
    "clip.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = clip.with_audio(original_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../output/video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building video ../output/video.mp4.\n",
      "MoviePy - Writing audio in videoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video ../output/video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ../output/video.mp4\n"
     ]
    }
   ],
   "source": [
    "clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
